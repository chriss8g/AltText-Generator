\begin{thebibliography}{1}

\bibitem{vinyals2015show}
Oriol Vinyals, Alexander Toshev, Samy Bengio, and Dumitru Erhan.
\newblock Show and tell: A neural image caption generator.
\newblock {\em arXiv preprint arXiv:1411.4555}, 2015.

\bibitem{xu2015show}
Kelvin Xu, Jimmy~Lei Ba, Ryan Kiros, Kyunghyun Cho, Aaron Courville, Ruslan Salakhutdinov, Richard~S. Zemel, and Yoshua Bengio.
\newblock Show, attend and tell: Neural image caption generation with visual attention.
\newblock {\em arXiv preprint arXiv:1502.03044}, 2015.

\bibitem{aneja2018convcap}
Jyoti Aneja, Aditya Deshpande, and Alexander~G. Schwing.
\newblock Convolutional image captioning.
\newblock {\em arXiv preprint arXiv:1805.09019}, 2018.

\bibitem{anderson2018bottom}
Peter Anderson, Xiaodong He, Chris Buehler, Damien Teney, Mark Johnson, Stephen Gould, and Lei Zhang.
\newblock Bottom-up and top-down attention for image captioning and visual question answering.
\newblock {\em arXiv preprint arXiv:1707.07998}, 2018.

\bibitem{lu2017knowing}
Jiasen Lu, Caiming Xiong, Devi Parikh, and Richard Socher.
\newblock Knowing when to look: Adaptive attention via a visual sentinel for image captioning.
\newblock {\em arXiv preprint arXiv:1612.01887}, 2017.

\bibitem{yu2019multimodal}
Jun Yu, Jing Li, Zhou Yu, and Qingming Huang.
\newblock Multimodal transformer with multi-view visual representation for image captioning.
\newblock {\em arXiv preprint arXiv:1905.07841}, 2019.

\bibitem{dosovitskiy2021image}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, and Neil Houlsby.
\newblock An image is worth 16x16 words: Transformers for image recognition at scale.
\newblock {\em arXiv preprint arXiv:2010.11929}, 2021.

\bibitem{radford2021learning}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, and Ilya Sutskever.
\newblock Learning transferable visual models from natural language supervision.
\newblock {\em arXiv preprint arXiv:2103.00020}, 2021.

\bibitem{li2022blip}
Junnan Li, Dongxu Li, Caiming Xiong, and Steven Hoi.
\newblock Blip: Bootstrapping language-image pre-training for unified vision-language understanding and generation.
\newblock {\em arXiv preprint arXiv:2201.12086}, 2022.

\end{thebibliography}
